{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca4252-0885-430d-9882-92ef59881c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from os.path import join, abspath, exists, pardir\n",
    "import tomlkit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.table import Table, join as tab_join, vstack\n",
    "import copy\n",
    "from numpy import array as a\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import pycatch22\n",
    "from tempfile import TemporaryDirectory\n",
    "import subprocess\n",
    "from astropy.stats import sigma_clipped_stats, sigma_clip\n",
    "from supersmoother import SuperSmoother\n",
    "import scipy.ndimage\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.timeseries import TimeSeries, aggregate_downsample\n",
    "from astropy.time import TimeDelta, Time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lightcurve import ASASSN_Lightcurve\n",
    "from utils import read_config, n_hist_bins, hist\n",
    "from data_preparation import prepare_lc, plot_prepared\n",
    "from metrics import fill_lc_gaps, calc_metrics, short_metric_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfffcd39-aa8d-4cff-8ff5-b9cc5fd5da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='.*dubious year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2c5d6-1c97-468b-82bd-2be936cc64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = read_config(\"config.toml\")\n",
    "data_dir = cfg[\"data_dir\"]\n",
    "data_link = cfg[\"data_link\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e87c52-5c18-423a-a69a-32cd86a1e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd $(data_dir) && curl $(data_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c86335-a46e-4110-b139-4c73d2b7c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dir = join(abspath(join(data_dir,os.pardir)),\"cleaned\")\n",
    "\n",
    "csv_path = join(abspath(join(data_dir,os.pardir)),\"asassn_rounded.csv\")\n",
    "\n",
    "outdir = \"out\"\n",
    "os.makedirs(outdir,exist_ok=True)\n",
    "\n",
    "def out(fname): return join(outdir,fname)\n",
    "def savefig(fname): plt.savefig(out(fname),dpi=300,bbox_inches=\"tight\")\n",
    "def load_old_lc(fname): return ASASSN_Lightcurve.from_dat_file(join(data_dir,fname))\n",
    "def load_cleaned_lc(fname): return ASASSN_Lightcurve.from_cleaned_file(join(cleaned_dir,fname))\n",
    "rng = np.random.default_rng()\n",
    "metadata = Table.read(csv_path)\n",
    "names = [ASASSN_Lightcurve.filename_from_id(i) for i in metadata[\"ID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe53d6-71b8-4e64-becd-d43d55d50fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_calculate_metrics(row,lc_is_cleaned=False):\n",
    "    fname = ASASSN_Lightcurve.filename_from_id(row[\"ID\"])\n",
    "    if lc_is_cleaned:\n",
    "        lc = load_cleaned_lc(fname)\n",
    "    else:\n",
    "        lc = load_old_lc(fname)\n",
    "\n",
    "    d_mag, d_times = prepare_lc(lc,row,do_preprocess=not lc_is_cleaned)\n",
    "    return calc_metrics(d_mag, d_times, lc.cadence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f07986-a542-426d-9809-1354a90eb15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = short_metric_names\n",
    "data = []\n",
    "classes = []\n",
    "ids = []\n",
    "for row in metadata[:10]:\n",
    "    metrics = process_and_calculate_metrics(row)\n",
    "    classification = row[\"ML_classification\"]\n",
    "    data.append(metrics)\n",
    "    ids.append(row['ID'])\n",
    "    classes.append(classification)\n",
    "    \n",
    "\n",
    "tab = Table(data=a(data),names=colnames)\n",
    "tab[\"class\"] = classes\n",
    "tab[\"ID\"] = ids\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb9f87-f365-4c93-927e-4b09bca29dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = config[\"metric_savedir\"]\n",
    "os.makedirs(savedir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1a5bc-7a28-4d74-a701-eb670baf34c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = short_metric_names\n",
    "data = []\n",
    "classes = []\n",
    "ids = []\n",
    "\n",
    "checkpoint_interval = 5000\n",
    "\n",
    "start_at = 350001\n",
    "current_iter = start_at\n",
    "for i, row in enumerate(tqdm(metadata[start_at:])):\n",
    "    try:\n",
    "        metrics = process_and_calculate_metrics(row)\n",
    "        classification = row[\"ML_classification\"]\n",
    "        data.append(metrics)\n",
    "        ids.append(row['ID'])\n",
    "        classes.append(classification)\n",
    "    except Exception as e:\n",
    "        with open(join(savedir,\"errors.txt\"),\"a+\") as f:\n",
    "            f.write(f\"Couldn't preprocess {row['ID']}: {e}\\n\")\n",
    "    current_iter = i + start_at\n",
    "    if current_iter and current_iter%checkpoint_interval == 0:\n",
    "        tab = Table(data=a(data),names=colnames)\n",
    "        tab[\"class\"] = classes\n",
    "        tab[\"ID\"] = ids\n",
    "        tab.write(join(savedir,f\"{current_iter-checkpoint_interval}_{current_iter}.csv\"),overwrite=True)\n",
    "        data = []\n",
    "        classes = []\n",
    "        ids = []\n",
    "        \n",
    "tab = Table(data=a(data),names=colnames)\n",
    "tab[\"class\"] = classes\n",
    "tab[\"ID\"] = ids\n",
    "tab.write(join(savedir,\"final.csv\"),overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90702edd-4c2b-4b43-9d35-3519446caad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "dir_list = os.listdir(savedir)\n",
    "for f in dir_list:\n",
    "    print(f)\n",
    "    tables.append(Table.read(os.path.join(savedir, f)))\n",
    "\n",
    "t = vstack(tables)\n",
    "unique_classes = np.unique(t[\"class\"])\n",
    "n=[len(np.where(t[\"class\"] == cls)[0]) for cls in unique_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60193e40-f84f-48c9-94cd-070cbe5298f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 5000  # classes with fewer than this many samples will be dropped (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ad029-58c9-4475-ad1a-4f424b66c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_classes_idx = np.where(np.array(n) > cutoff)[0]\n",
    "allowed_classes = np.array(unique_classes[allowed_classes_idx])\n",
    "t = t[np.isin(t[\"class\"], allowed_classes)]\n",
    "rng = np.random.default_rng()\n",
    "i = np.arange(len(t))\n",
    "rng.shuffle(i)\n",
    "t = t[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ecdc4e-0469-4b76-8eb4-6c8ec46d8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = 0.7\n",
    "VAL = 0.2\n",
    "TEST = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb841f2a-3c17-4dec-a251-e88e2cfe8cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train = t[:int(TRAIN*len(t))]\n",
    "t_valid = t[int(TRAIN*len(t)) : int(TRAIN*len(t)) + int(VAL*len(t))]\n",
    "t_test = t[int(TRAIN*len(t)) + int(VAL*len(t)):]\n",
    "len(t_train)/len(t), len(t_valid)/len(t), len(t_test)/len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d083c5-e13f-42fa-879c-4463e602580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TABDIR = config[\"table_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c26abd-8eb6-4315-bfb9-99c66756d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train.write(join(TABDIR,\"big_train.csv\")\n",
    "t_valid.write(join(TABDIR,\"valid.csv\")\n",
    "t_test.write(join(TABDIR,\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a2bd9-26ad-415b-8612-49cd9c506e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance the classes\n",
    "\n",
    "n = cutoff\n",
    "rand_list = []\n",
    "for c in allowed_classes:\n",
    "    indices = np.where(t_train[\"class\"] == c)[0]\n",
    "    if len(indices) >= n:\n",
    "        chosen_indices = rng.choice(indices, n, replace=False)\n",
    "    else:\n",
    "        chosen_indices = indices\n",
    "    rand_list.extend(chosen_indices)\n",
    "\n",
    "split_table = t_train[rand_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ddf4f-092f-4814-b7e5-662ade353e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_table.write(join(TABDIR,\"train.csv\"),overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
